# -*- coding: utf-8 -*-
"""Model Machine Learning dengan Data Time Series yohan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lAkfB8jct6N5puMD4INu8m-8AtRJr8Ek

**Nama : Yohan Permana**
"""

!pip install -q kaggle
#digunakan untuk menginstal paket Python bernama "kaggle" menggunakan perintah pip dari dalam lingkungan Jupyter Notebook atau notebook berbasis Python lainnya.

# digunakan untuk mengunggah file
from google.colab import files
files.upload()

#digunakan untuk membuat dan mengonfigurasi direktori .kaggle serta mengelola file kaggle.json
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets list

#Perintah ini digunakan untuk mengunduh dataset dengan nama delhi-weather-data dari Kaggle menggunakan perintah kaggle datasets download.
!kaggle datasets download -d mahirkukreja/delhi-weather-data

# digunakan untuk membuat direktori baru bernama bbcnewsarchivedelhi-weather-data, mengekstrak isi dari file delhi-weather-data.zip ke dalam direktori tersebut, dan menampilkan daftar file yang telah diekstrak.
!mkdir delhi-weather-data
!unzip delhi-weather-data.zip -d delhi-weather-data
!ls delhi-weather-data

import pandas as pd

# Baca file CSV ke dalam DataFrame
df = pd.read_csv('delhi-weather-data/testset.csv')

# Tampilkan 10 baris pertama dengan beberapa gaya
styled_df = df.head(10).style.set_properties(**{'background-color': 'lightyellow',
                                                'color': 'black',
                                                'border': '1px solid black'})

# Menampilkan DataFrame yang ditata
styled_df

# Menampilkan informasi dasar tentang DataFrame
print("\033[1mDataFrame Information:\033[0m")
df.info()

# Menampilkan jumlah nilai nol di setiap kolom
print("\n\033[1mNull Value Summary:\033[0m")
null_summary = df.isnull().sum().to_frame(name='Null Count').sort_values(by='Null Count', ascending=False)
null_summary.style.set_properties(**{'background-color': 'lightcoral',
                                     'color': 'black',
                                     'border': '1px solid black'})

# Konversi kolom 'datetime_utc' ke tipe data datetime
df['datetime_utc'] = pd.to_datetime(df['datetime_utc'])

# Tampilkan lima baris pertama dari kolom 'datetime_utc'
df['datetime_utc'].head()

# Isi nilai-nilai kosong (NaN) dalam kolom '_tempm' dengan nilai rata-rata
df[' _tempm'].fillna(df[' _tempm'].mean(), inplace=True)

# Pilih hanya kolom 'datetime_utc' dan '_tempm' dalam DataFrame
df = df[['datetime_utc', ' _tempm' ]]

# Tampilkan sepuluh baris pertama dari DataFrame yang telah dimodifikasi
df.head(10)

class CustomDataFrameInfo:
    def __init__(self, dataframe):
        self.dataframe = dataframe

    def custom_info(self):
        print("Custom Information:")
        print(f"Number of rows: {len(self.dataframe)}")
        print(f"Number of columns: {len(self.dataframe.columns)}")
        print("\nData Types:")
        print(self.dataframe.dtypes)

# Membuat instance dari kelas CustomDataFrameInfo
custom_info_df = CustomDataFrameInfo(df)

# Memanggil metode custom_info() untuk menampilkan informasi kustom
custom_info_df.custom_info()

"""*Proses Modeling dan Plot*"""

import pandas as pd


new_delhi = df[['datetime_utc', ' _tempm']].copy()

# Menambahkan kolom 'just_date' yang berisi tanggal
new_delhi['just_date'] = new_delhi['datetime_utc'].dt.date

# Membuat DataFrame baru tanpa kolom 'datetime_utc'
new_delhi_final = new_delhi.drop('datetime_utc', axis=1)

# Mengatur 'just_date' sebagai indeks
new_delhi_final.set_index('just_date', inplace=True)

# Menampilkan pesan kustom
print("Kolom 'datetime_utc' dihapus, dan 'just_date' dijadikan indeks.")
print("Hasil DataFrame:")
print(new_delhi_final.head())

new_delhi_final.info()

import matplotlib.pyplot as plt
import seaborn as sns  # Menambahkan seaborn untuk gaya yang lebih menarik

# Data baru (contoh)
dates = ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05']
new_delhi_final = [20, 22, 18, 25, 23]

# Plotting dengan gaya seaborn
sns.set(style="whitegrid")  # Mengatur gaya latar belakang

plt.figure(figsize=(14, 6))

# Gunakan lineplot untuk tampilan yang lebih modern dan informatif
sns.lineplot(x=dates, y=new_delhi_final, marker='o', color='b', label='Temperature')

# Menambahkan judul dan label sumbu
plt.title('Delhi Weather', fontsize=16)
plt.xlabel('Date', fontsize=14)
plt.ylabel('Temperature', fontsize=14)

# Menambahkan grid untuk memudahkan membaca data
plt.grid(True, linestyle='--', alpha=0.7)

# Menambahkan label pada titik data
for i, txt in enumerate(new_delhi_final):
    plt.annotate(f'{txt}Â°C', (dates[i], new_delhi_final[i]), textcoords="offset points", xytext=(0,10), ha='center')

# Menambahkan legenda
plt.legend()

# Menampilkan plot
plt.show()

# mengambil data nilai
date = df['datetime_utc'].values
temp = df[' _tempm'].values

import tensorflow as tf

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    # Menambahkan dimensi tambahan ke series menggunakan tf.expand_dims
    series = tf.expand_dims(series, axis=-1)

    # Membuat tf.data.Dataset dari series
    ds = tf.data.Dataset.from_tensor_slices(series)

    # Membagi dataset menjadi jendela berukuran window_size + 1 dengan pergeseran 1
    # drop_remainder=True memastikan bahwa jendela terakhir yang mungkin lebih kecil diabaikan
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)

    # Mengubah dataset menjadi bentuk flat_map agar dapat diatur sebagai batch
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))

    # Mengacak dataset menggunakan nilai shuffle_buffer yang diberikan
    ds = ds.shuffle(shuffle_buffer)

    # Memetakan setiap elemen dataset menjadi pasangan input-output
    ds = ds.map(lambda w: (w[:-1], w[-1:]))

    # Membuat batch dari dataset dengan ukuran batch_size
    # prefetch(1) memungkinkan prefetching satu batch ke depan untuk mempercepat pelatihan
    return ds.batch(batch_size).prefetch(1)

from sklearn.model_selection import train_test_split

# Membagi dataset menjadi data pelatihan (train) dan data uji (test)
# temp adalah fitur atau atribut dataset
# date adalah label atau target dataset
# test_size=0.2 mengindikasikan bahwa 20% dari data akan digunakan sebagai data uji
# random_state=0 memberikan seed untuk pengacakan, sehingga hasilnya dapat direproduksi
# shuffle=False memastikan bahwa data tidak diacak sebelum pembagian, menggunakan urutan asli
x_train, x_test, y_train, y_test = train_test_split(temp, date, test_size=0.2, random_state=0, shuffle=False)

# Mencetak panjang data pelatihan dan data uji
print(len(x_train), len(x_test))

from keras.layers import Dense, LSTM
import tensorflow as tf
from tensorflow.keras.optimizers import SGD

# Membuat dataset menggunakan fungsi windowed_dataset untuk data pelatihan dan data uji
data_x_train = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=5000)
data_x_test = windowed_dataset(x_test, window_size=60, batch_size=100, shuffle_buffer=5000)

# Membuat model menggunakan Sequential API dari Keras
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(filters=32, kernel_size=5,
                           strides=1, padding="causal",
                           activation="relu",
                           input_shape=[None, 1]),
    tf.keras.layers.LSTM(64, return_sequences=True),
    tf.keras.layers.LSTM(64, return_sequences=True),
    tf.keras.layers.Dense(30, activation="relu"),
    tf.keras.layers.Dense(10, activation="relu"),
    tf.keras.layers.Dense(1),
    tf.keras.layers.Lambda(lambda x: x * 400)
])

# Membuat schedule untuk learning rate berdasarkan epoch
lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    lambda epoch: 1e-8 * 10**(epoch / 20))

# Menggunakan stochastic gradient descent (SGD) sebagai optimizer
optimizer = SGD(learning_rate=1e-8, momentum=0.9)

# Mengompilasi model dengan menggunakan fungsi loss Huber dan metric MAE (Mean Absolute Error)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

max_value = df[' _tempm'].max()
print('Max value : ')
print(max_value)

min_value = df[' _tempm'].min()
print('Min Value : ')
print(min_value)

# Menghitung 10% dari selisih antara 90.0 dan 1.0
temperature_difference = 90.0 - 1.0
percentage = 10
result = temperature_difference * (percentage / 100)

# Menampilkan hasil perhitungan
print("10% of the temperature difference between 90.0 and 1.0 is:", result)

# callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')< x):
      self.model.stop_training = True
      print("\nMAE of the model < 10% of data scale")
callbacks = myCallback()

tf.keras.backend.set_floatx('float64')
history = model.fit(data_x_train ,epochs=10, validation_data=data_x_test, callbacks=[callbacks])

"""Visualisasi Loss Model"""

import matplotlib.pyplot as plt

# Melihat gaya plot yang tersedia di Matplotlib
plt.style.available
plt.style.use('seaborn-darkgrid')  # Anda dapat memilih gaya yang sesuai dengan preferensi Anda

# Plot loss dan val_loss dengan warna dan marker yang berbeda
plt.plot(history.history['loss'], label='Training Loss', color='blue', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', color='red', marker='x')

# Menambahkan judul dan label sumbu
plt.title('Model Loss Over Epochs', fontsize=16)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss', fontsize=12)

# Menambahkan legenda
plt.legend()

# Menambahkan grid untuk mempermudah pembacaan grafik
plt.grid(True)

# Menampilkan plot
plt.show()

"""*Visualisasi MAE*"""

import matplotlib.pyplot as plt

# Melihat gaya plot yang tersedia di Matplotlib
plt.style.available
plt.style.use('seaborn-darkgrid')  # Anda dapat memilih gaya yang sesuai dengan preferensi Anda

# Plot mae dan val_mae dengan warna dan marker yang berbeda
plt.plot(history.history['mae'], label='Training MAE', color='green', marker='s')
plt.plot(history.history['val_mae'], label='Validation MAE', color='orange', marker='^')

# Menambahkan judul dan label sumbu
plt.title('Mean Absolute Error Over Epochs', fontsize=16)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('MAE', fontsize=12)

# Menambahkan legenda
plt.legend()

# Menambahkan grid untuk mempermudah pembacaan grafik
plt.grid(True)

# Menampilkan plot
plt.show()